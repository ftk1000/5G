{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parse_3gpp_v2b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftk1000/5G/blob/master/parse_3gpp_v2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsN_lkIyCLfw",
        "colab_type": "text"
      },
      "source": [
        "# Parse 3GPP document\n",
        "2020.08.19\n",
        "\n",
        "parse_3gpp_v2b.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q9Bo-aGP5wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# parse_3gpp_v2.py\n",
        "# 2020.08.19\n",
        "#---------------------------------------------\n",
        "#  README:\n",
        "#---------------------------------------------\n",
        "#prepare data set : parse 3GPP 36523-1-f00_s07_01.txt and \n",
        "#extract sentences corresponding to \"test case name\", \"with\", \"when\", \"then\"\n",
        "#\n",
        "# SOURCE DOCUMENT\n",
        "# LTE; Evolved Universal Terrestrial Radio Access (E-UTRA) and Evolved Packet Core (EPC);\n",
        "# User Equipment (UE) conformance specification; Part 1: Protocol conformance specification\n",
        "# 3GPP TS 36.523-1\n",
        "\n",
        "# downloaded *.DOC files are here:  36523-1-f00.zip\n",
        "# we will use only of them converted to TXT format\n",
        "#\n",
        "#INPUT DATA:\n",
        "# 36523-1-f00_s07_01.txt\n",
        "#\n",
        "#36523-1-f00_s07_01.txt files was generated from \n",
        "#36523-1-f00_s07_01.DOC file located in\n",
        "#\n",
        "#OUTPUT:\n",
        "# 36523-1-f00_s07_01_tests.csv   \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import random"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGqlRJBZEsMe",
        "colab_type": "text"
      },
      "source": [
        "# Authenticate, create the PyDrive client, and READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTkNYef5tQlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fe2bdc01-610d-4037-b2d4-b915461314d7"
      },
      "source": [
        "### Here are the instructions how to read a file from Gdrive\n",
        "# https://buomsoo-kim.github.io/colab/2018/04/16/Importing-files-from-Google-Drive-in-Google-Colab.md/\n",
        "\n",
        "# shareble_link = 'https://drive.google.com/file/d/1jNGAf5O6U4Cr4GbWK_DpCxIuxv7-BQ2c/view?usp=sharing';  file_id = '1jNGAf5O6U4Cr4GbWK_DpCxIuxv7-BQ2c'\n",
        "# shareble_link = 'https://drive.google.com/file/d/0B1Iyay9XxksvMG9wLUpFQm1Hbnc/view?usp=sharing';  file_id = '0B1Iyay9XxksvMG9wLUpFQm1Hbnc'\n",
        "shareble_link = 'https://drive.google.com/file/d/18agBYxgWJ4dVZGOYK1mil1RDhjvQL8e1/view?usp=sharing'; file_id = '18agBYxgWJ4dVZGOYK1mil1RDhjvQL8e1'\n",
        "\n",
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (49.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM6kog8hEect",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#see Step 6 https://buomsoo-kim.github.io/colab/2018/04/16/Importing-files-from-Google-Drive-in-Google-Colab.md/\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx_HHdnuEzXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':file_id})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('36523-1-f00_s07_01.zip') "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MchwYeW0txL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6bf9ec99-d4c9-4abc-84c5-8d3726de9447"
      },
      "source": [
        "# !ls -l\n",
        "!unzip 36523-1-f00_s07_01.zip"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  36523-1-f00_s07_01.zip\n",
            "replace 36523-1-f00_s07_01.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: 36523-1-f00_s07_01.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgpo63p_uGue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !more RespondentTypeREADME.txt\n",
        "wd = './'\n",
        "file_name = wd+'36523-1-f00_s07_01.txt'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGds5v-eFOi1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30c4af50-1b18-4c89-c60c-136c2845d1c4"
      },
      "source": [
        "# to deal with non-ascii codes read this\n",
        "# https://stackoverflow.com/questions/22216076/unicodedecodeerror-utf8-codec-cant-decode-byte-0xa5-in-position-0-invalid-s\n",
        "# import codecs      # f = codecs.open(file_name, \"r\", encoding= 'unicode_escape')\n",
        "# file_name = '36523-1-f00_s07_01.txt'\n",
        "with open(file=file_name, mode='r', encoding='unicode_escape') as f:\n",
        "    lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "printable = set(string.printable)\n",
        "lines2 = [  ''.join(filter(lambda x: x in printable, s)) for s in lines  ]\n",
        "assert len(lines2)==len(lines)\n",
        "print(len(lines))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EWKProuSBUh",
        "colab_type": "text"
      },
      "source": [
        "# TAKE A LOOK AT DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRUvV7jR2OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "bc637129-751b-4066-c1d5-c71b25b5e18b"
      },
      "source": [
        "# Show a few lines describing a test case\n",
        "k=218\n",
        "lines[k-4:k+10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '7.1.1.1.3.3\\tSpecific message contents\\n',\n",
              " 'None.\\n',\n",
              " '7.1.1.1a\\tCCCH mapped to UL SCH/ DL-SCH / UE Cat 0\\n',\n",
              " '7.1.1.1a.1\\tTest Purpose (TP)\\n',\n",
              " '(1)\\n',\n",
              " 'with { UE in E-UTRA RRC_IDLE state }\\n',\n",
              " 'ensure that {\\n',\n",
              " '  when { UE receives a Paging message including a matched identity }\\n',\n",
              " '    then { UE responds with a RRCConnectionRequest message in a MAC PDU on UL SCH on CCCH indicating LCID \\x9201011\\x92  }\\n',\n",
              " '            }\\n',\n",
              " '\\n',\n",
              " '7.1.1.1a.2\\tConformance requirements\\n',\n",
              " 'References: The conformance requirements covered in the current TC are specified in: TS 36.321, clause 5.3.3, 5.11, 6.1.2 and 6.2.1.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGupeoExR7bQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1cceb8f9-4b7a-4424-e73a-476f995ad832"
      },
      "source": [
        "# Some 'with' are followed by '{', some by '('\n",
        "print(lines[220].strip())\n",
        "print(lines[16000].strip())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with { UE in E-UTRA RRC_IDLE state }\n",
            "with ( UE in E-UTRA RRC_CONNECTED state )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXvbTr7w5Xz",
        "colab_type": "text"
      },
      "source": [
        "# PARSING/SEARCH/REGEX FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYEveiHIw4Jw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "458182d7-6be2-4e59-e80e-886cd8a3a2e0"
      },
      "source": [
        "# find line numbers that contain PATTERN\n",
        "def find_lineNums(lines, pattern):\n",
        "    test_idx = []\n",
        "    for i in range(len(lines)):\n",
        "      line = lines[i].strip();  # print(line)\n",
        "      if line.find(pattern) >=0 :\n",
        "        test_idx.append(i)\n",
        "    return test_idx\n",
        "\n",
        "PATTERN = \"Test Purpose (TP)\"\n",
        "test_idx = find_lineNums(lines=lines, pattern= PATTERN)    \n",
        "print(test_idx)\n",
        "print(\"patterns found =\",len(test_idx))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36, 218, 352, 508, 873, 1087, 1243, 1596, 1949, 2241, 2621, 2782, 2973, 3196, 3435, 3725, 4275, 5016, 5605, 5754, 6360, 6621, 6707, 6933, 7193, 7507, 7807, 8127, 8250, 8544, 9076, 9544, 10221, 10660, 11099, 11743, 12380, 12620, 13509, 13656, 14067, 14273, 15027, 15295, 15383, 15532, 15998, 16568, 16809, 17228, 17548, 17768, 18205, 18605, 18918, 19220, 19883, 20194, 20455, 20758, 21173, 21646, 21989, 22399, 22661, 23370, 23385, 23748, 24075, 24312, 24649, 24963, 25424, 25460, 25765, 26315, 26532, 26903, 27753, 27920, 28137, 28320, 28428, 28535, 28926, 29245, 29564, 29878, 30213, 30548, 34821, 38947, 43126, 47278, 51785, 56037, 61926, 67310, 72686, 78107, 83529, 84824, 86116, 92189, 93231, 94224, 98418, 99255, 99901, 100314, 100705, 101044, 101333, 101881]\n",
            "patterns found = 114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdlHsACwKqQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "245fb337-cb84-4d4a-d102-5d29bfbed655"
      },
      "source": [
        "import re\n",
        "R = re.compile(r\"^\\(\\d+\\)\")\n",
        "\n",
        "#for line in lines:\n",
        "#    M = R.search(line)\n",
        "#    if M:\n",
        "#        print(M.string)\n",
        "# keep looking for '(\\d)' until find 'Conformance requirements'\n",
        "# or the next test (ix2)\n",
        "def find_idx_subtests(ix1,ix2):\n",
        "  ix_subtest = []\n",
        "  for i in range(ix1,ix2):\n",
        "    M = R.search(lines[i])\n",
        "    if M:\n",
        "      #lines[i][0]=='(':\n",
        "      ix_subtest.append(i)\n",
        "      # print('==> lineNum =',i, \"  line=\", lines[i].strip())\n",
        "    if lines[i].find(\"Conformance requirements\") >=0 :\n",
        "        ix_subtest.append(i)   #conf_req_line = i\n",
        "        break;\n",
        "  return ix_subtest\n",
        "#%%\n",
        "k=46\n",
        "ix1=test_idx[k]; ix2=test_idx[k+1]\n",
        "subtests = find_idx_subtests(ix1, ix2)  \n",
        "for p in range(len(subtests)):\n",
        "    print(subtests[p], '    ',lines[subtests[p]].strip() )"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15999      (1)\n",
            "16006      (2)\n",
            "16013      (3)\n",
            "16020      (4)\n",
            "16026      (5)\n",
            "16033      (6)\n",
            "16039      (7)\n",
            "16045      (8)\n",
            "16052      7.1.4.6.2\tConformance requirements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjLp9jmgyDPt",
        "colab_type": "text"
      },
      "source": [
        "# BUILD A DATA FRAME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9_yKa55oi7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b9a18c14-bfde-4156-8205-799e38181b87"
      },
      "source": [
        "d = pd.DataFrame(columns=['doc','test_sec', 'test_name', 'test_num',  'with', 'when', 'then'])\n",
        "doc_name = file_name.split('.')[0]\n",
        "#d.loc[0] = ['7.1.1.1',  'CCCH mapped to','1', 'with aa', 'when bb', 'then cc'] \n",
        "\n",
        "# BUILD THE DATA BASE\n",
        "df_index = 0\n",
        "for k in range(len(test_idx)-1):\n",
        "    ix=test_idx[k]\n",
        "    ix2=test_idx[k+1]\n",
        "    #def update_df(ix):\n",
        "    [sec_num, test_name] = lines[ix-1].strip().split('\\t')\n",
        "    ix_subtests = find_idx_subtests(ix,ix2)\n",
        "    for p in range(len(ix_subtests)-1):\n",
        "        index = ix_subtests[p]\n",
        "        \n",
        "        with_kw = when_kw = then_kw = ''\n",
        "        while index < ix_subtests[p+1]:\n",
        "            line = lines[index].strip()\n",
        "            if line.find('with') >=0 :\n",
        "                with_kw = line[len('with'):].strip()[1:-1].strip()\n",
        "            if line.find('when') >=0 :\n",
        "                when_kw = line[len('when'):].strip()[1:-1].strip()\n",
        "            if line.find('then') >=0 :\n",
        "                then_kw = line[len('then'):].strip()[1:-1].strip()\n",
        "            index += 1\n",
        "            \n",
        "        d.loc[df_index] = [doc_name, sec_num,  test_name, p+1, with_kw, when_kw, then_kw] \n",
        "        df_index += 1\n",
        "\n",
        "print(d.shape)\n",
        "d.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(279, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>test_sec</th>\n",
              "      <th>test_name</th>\n",
              "      <th>test_num</th>\n",
              "      <th>with</th>\n",
              "      <th>when</th>\n",
              "      <th>then</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_IDLE state and after transmit...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE discards the MAC PDU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE forwards to upper layers the disassembled a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1a</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / UE Cat 0</td>\n",
              "      <td>1</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "      <td>UE receives a Paging message including a match...</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.2</td>\n",
              "      <td>DTCH or DCCH mapped to UL SCH/ DL-SCH / Reserv...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_Connected state with DRB [Log...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE shall not forward the disassembled and demu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.2</td>\n",
              "      <td>DTCH or DCCH mapped to UL SCH/ DL-SCH / Reserv...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE shall forward the disassembled and demultip...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  doc  ...                                               then\n",
              "0  36523-1-f00_s07_01  ...                            UE discards the MAC PDU\n",
              "1  36523-1-f00_s07_01  ...  UE forwards to upper layers the disassembled a...\n",
              "2  36523-1-f00_s07_01  ...  UE responds with a RRCConnectionRequest messag...\n",
              "3  36523-1-f00_s07_01  ...  UE shall not forward the disassembled and demu...\n",
              "4  36523-1-f00_s07_01  ...  UE shall forward the disassembled and demultip...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TeLUzfyUv2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd='./'\n",
        "d.to_csv(wd+doc_name+'_tests.csv')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgEgseMTzHvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #%% GENERATE TRAIN AND TEST SETS\n",
        "# import numpy as np\n",
        "# txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))\n",
        "# lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )\n",
        "\n",
        "# assert len(lbl)==len(txt)\n",
        "\n",
        "# # Shuffle and split\n",
        "# idx = np.random.permutation(len(txt))\n",
        "# x,y = txt[idx], lbl[idx]\n",
        "# df=pd.DataFrame({'sentence':x,'label':y})"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7V_Hho7UnPM",
        "colab_type": "text"
      },
      "source": [
        "# SPLIT DATA FRAME INTO TRAIN AND TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmsD69flTgJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ea42524-ff6b-40f4-bb3c-7b564632d598"
      },
      "source": [
        "np.random.seed(seed=60)\n",
        "# idx = np.random.permutation(d.shape[0])\n",
        "\n",
        "test_rows_num = 5\n",
        "# test_rows = random.sample( range(0,d.shape[0]), test_rows_num ) \n",
        "# test_rows=[0,1,2]\n",
        "test_rows= [156, 253, 209, 43, 271]\n",
        "print('test_rows=', test_rows)\n",
        "d_test = d.iloc[test_rows]\n",
        "d_train = d.drop(test_rows)\n",
        "\n",
        "def get_X_Y(d):\n",
        "    txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))\n",
        "    lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )\n",
        "    return txt, lbl\n",
        "\n",
        "idx = np.random.permutation(len(d_train))\n",
        "X_train, y_train = get_X_Y(d_train.iloc[idx])\n",
        "X_test,  y_test  = get_X_Y(d_test)\n",
        "\n",
        "assert(len(X_train)==len(y_train))\n",
        "assert(len(X_test)==len(y_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_rows= [156, 253, 209, 43, 271]\n",
            "822\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WSXglhyViRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set\n",
        "X_test_counts  = count_vect.transform(X_test)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnAfi3xzlhq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "607a0200-6366-4d89-b209-dd7b714b367c"
      },
      "source": [
        "#%% XGBoost: XGB \n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)\n",
        "\n",
        "xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.005 ).fit(X_train_counts, y_train)\n",
        "predicted = xgbmodel.predict(X_test_counts)\n",
        "res=np.mean(predicted == y_test)\n",
        "print(res)\n",
        "#oac_df.loc['XGB']=res"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7irhA-0g0wTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9541dac2-62c8-49eb-b5ee-5fc9ac210dbd"
      },
      "source": [
        "# print(X_test)\n",
        "print(y_test)\n",
        "print(predicted)\n",
        "\n",
        "def compare_tuples(test_rows_num, y_test, predicted):\n",
        "  test_tuples = []\n",
        "  pred_tuples = []\n",
        "  for k in range(test_rows_num):\n",
        "    test_tuples.append([y_test[k], y_test[k+test_rows_num], y_test[k+2*test_rows_num]])\n",
        "    pred_tuples.append([predicted[k], predicted[k+test_rows_num], predicted[k+2*test_rows_num]])\n",
        "\n",
        "  d_tuples = pd.DataFrame( {'test_tuples':test_tuples, 'pred_tuples':pred_tuples} )\n",
        "  d_tuples['match']=d_tuples['test_tuples']==d_tuples['pred_tuples']\n",
        "  return d_tuples\n",
        "\n",
        "compare_tuples(test_rows_num, y_test, predicted)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n",
            "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_tuples</th>\n",
              "      <th>pred_tuples</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_tuples pred_tuples  match\n",
              "0   [0, 1, 2]   [0, 1, 2]   True\n",
              "1   [0, 1, 2]   [0, 1, 2]   True\n",
              "2   [0, 1, 2]   [0, 1, 2]   True\n",
              "3   [0, 1, 2]   [0, 1, 2]   True\n",
              "4   [0, 1, 2]   [0, 1, 2]   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhiB7R-0_Ki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b0245168-bed6-4daa-db82-bef7dc461332"
      },
      "source": [
        "X_test[y_test!=predicted]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['UE performs non-adaptive retransmission of the MAC PDU with redundancy version toggled by one of the last (re)transmission [0,2,3,1 order]',\n",
              "       'UE inserts a R/R/E/LCID field in the MAC header and a MAC SDU or a MAC control element starts at the next byte',\n",
              "       'UE responds with a RRCConnectionRequest message in a MAC PDU on UL SCH on CCCH indicating LCID \\x9201011\\x92'],\n",
              "      dtype='<U219')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULiK1QF1K6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5f85a59a-4ff3-4438-d21d-42524565fd7f"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['UE in E-UTRA RRC_IDLE state and after transmitting a RRCConnectionRequest message',\n",
              "       'UE receives a MAC PDU on DL SCH and addressed to its T-CRNTI with value \\x9100000\\x92B as LCID',\n",
              "       'UE responds with a RRCConnectionRequest message in a MAC PDU on UL SCH on CCCH indicating LCID \\x9201011\\x92',\n",
              "       'UE receives a MAC PDU on DL SCH and addressed to its T-CRNTI but including a reserved value for LCID',\n",
              "       'UE receives a MAC PDU on DL SCH and addressed to its T-CRNTI with value \\x9100000\\x92B as LCID',\n",
              "       'UE receives a Paging message including a matched identity',\n",
              "       'UE discards the MAC PDU',\n",
              "       'UE forwards to upper layers the disassembled and demultiplexed SDU on logical channel CCCH',\n",
              "       'UE responds with a RRCConnectionRequest message in a MAC PDU on UL SCH on CCCH indicating LCID \\x9201011\\x92'],\n",
              "      dtype='<U102')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JABGLjTe1TsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "0c989fff-85dd-4330-87c2-c5b42b411eb3"
      },
      "source": [
        "d.head(n=3)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>test_sec</th>\n",
              "      <th>test_name</th>\n",
              "      <th>test_num</th>\n",
              "      <th>with</th>\n",
              "      <th>when</th>\n",
              "      <th>then</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_IDLE state and after transmit...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE discards the MAC PDU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE forwards to upper layers the disassembled a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36523-1-f00_s07_01</td>\n",
              "      <td>7.1.1.1a</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / UE Cat 0</td>\n",
              "      <td>1</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "      <td>UE receives a Paging message including a match...</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  doc  ...                                               then\n",
              "0  36523-1-f00_s07_01  ...                            UE discards the MAC PDU\n",
              "1  36523-1-f00_s07_01  ...  UE forwards to upper layers the disassembled a...\n",
              "2  36523-1-f00_s07_01  ...  UE responds with a RRCConnectionRequest messag...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMw2xdm2150R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%   COPIED FROM\n",
        "# https://gitlab.verizon.com/atf/atf-development/atf-data-sciences/-/blob/master/ML_models/atf_xgb_classifier.py\n",
        "\n",
        "# df2=pd.DataFrame({'sentences':data,'labels':labels})\n",
        "def compare_classifiers_v2(X_train, y_train, X_test, y_test):\n",
        "#    VALIDATION_SPLIT = 0.3\n",
        "    # np.random.seed(seed=seedval)\n",
        "    # indices = np.arange(d2.shape[0]) # get sequence of row index\n",
        "    # np.random.shuffle(indices) # shuffle the row indexes\n",
        "    # data   = d2['sentences'][indices] # shuffle data/product-titles/x-axis\n",
        "    # labels = d2['labels'][indices]\n",
        "    # #\n",
        "    # from sklearn.model_selection import train_test_split\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_fraction, random_state=42)\n",
        "    \n",
        "#    #%% COMPARE  TRAIN  AND  TEST  SET DISTRIBUTIONS\n",
        "#    vdf=pd.concat([y_train.value_counts(normalize=True).round(3) * 100, \n",
        "#                   y_test.value_counts(normalize=True).round(3) * 100],\n",
        "#    sort =False, axis=1,ignore_index=True )\n",
        "#    vdf.columns = ['train','test']\n",
        "#    vdf.to_csv(wd+\"comp_train_and_test_lables.csv\")\n",
        "    \n",
        "    #%   ========================================================\n",
        "    # INITIALIZE OAC SUMMARY TABLE\n",
        "    # import numpy\n",
        "    models = ['NB', 'NB+TF', 'NB+TFIDF', 'SVM', 'SVM+TF', 'SVM+TFIDF', 'XGB', 'XGB+TF', 'XGB+TFIDF']\n",
        "    oacs = np.zeros(len(models))    \n",
        "    oac_df = pd.DataFrame( {'oac':oacs}, index=models )\n",
        "    oac_df    \n",
        "    \n",
        "    \n",
        "    #%  DEFINE THREE TRAIN SETS\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    count_vect = CountVectorizer()\n",
        "    X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set\n",
        "    X_test_counts  = count_vect.transform(X_test)\n",
        "    \n",
        "    #%\n",
        "    from sklearn.feature_extraction.text import TfidfTransformer\n",
        "    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "    X_train_tf = tf_transformer.transform(X_train_counts)  # TF train set \n",
        "    X_test_tf  = tf_transformer.transform(X_test_counts)\n",
        "    #%\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)  # TFIDF Train set\n",
        "    X_test_tfidf  = tfidf_transformer.transform(X_test_counts)\n",
        "    \n",
        "    #% XGBoost: XGB \n",
        "    import xgboost as xgb\n",
        "    import warnings\n",
        "    warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)\n",
        "    \n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_counts, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_counts, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_counts)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB']=res\n",
        "    print('XGB', res)\n",
        "    \n",
        "    #% XGBoost: XGB + TF\n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tf, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tf, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_tf)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB+TF']=res\n",
        "    print('XGB+TF', res)\n",
        "    \n",
        "    #% XGB+TFIDF\n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tfidf, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tfidf, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_tfidf)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB+TFIDF']=res\n",
        "    print('XGB+TFIDF', res)\n",
        "    \n",
        "    #% Plain NB Classifier\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "    #clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        #('tfidf', TfidfTransformer()),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB']=res\n",
        "    print('NB', res)\n",
        "    \n",
        "    #% NB iwth TF\n",
        "    # TfidfTransformer(use_idf=False)\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB+TF']=res\n",
        "    print('NB+TF', res)\n",
        "\n",
        "    #%\n",
        "#    lbls=[ x for x in set(labels)]\n",
        "#    print(lbls)\n",
        "#    cf = cmdf(y_test, predicted, lbls)\n",
        "#    cf.to_csv(wd+'xgb_tf_cf.csv')\n",
        "    \n",
        "    #% NB with TFIDF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB+TFIDF']=res\n",
        "    print('NB+TFIDF', res)\n",
        "\n",
        "\n",
        "    \n",
        "    #% Plain SVM\n",
        "    from sklearn.linear_model import SGDClassifier    \n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "    #     ('tfidf', TfidfTransformer()),\n",
        "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM']=res\n",
        "    print('SVM', res)\n",
        "\n",
        "    \n",
        "    #% SVM with TF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "        ('clf',  SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM+TF']=res\n",
        "    print('SVM+TF', res)\n",
        "    \n",
        "    #% SVM with TFIDF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM+TFIDF']=res\n",
        "    print('SVM+TFIDF', res)\n",
        "    \n",
        "    return oac_df    \n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_hdX8RP3529",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "b38f7d96-19d1-4a0c-9ccf-7e19730a020d"
      },
      "source": [
        "oac_df = compare_classifiers_v2(X_train, y_train, X_test, y_test)\n",
        "oac_df"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGB 0.7777777777777778\n",
            "XGB+TF 0.7777777777777778\n",
            "XGB+TFIDF 0.7777777777777778\n",
            "NB 0.6666666666666666\n",
            "NB+TF 0.6666666666666666\n",
            "NB+TFIDF 0.6666666666666666\n",
            "SVM 0.7777777777777778\n",
            "SVM+TF 0.7777777777777778\n",
            "SVM+TFIDF 0.6666666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>oac</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB+TF</th>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB+TFIDF</th>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM+TF</th>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM+TFIDF</th>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB+TF</th>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB+TFIDF</th>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                oac\n",
              "NB         0.666667\n",
              "NB+TF      0.666667\n",
              "NB+TFIDF   0.666667\n",
              "SVM        0.777778\n",
              "SVM+TF     0.777778\n",
              "SVM+TFIDF  0.666667\n",
              "XGB        0.777778\n",
              "XGB+TF     0.777778\n",
              "XGB+TFIDF  0.777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kQOqlsa377f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}