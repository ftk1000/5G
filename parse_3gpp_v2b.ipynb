{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parse_3gpp_v2b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftk1000/5G/blob/master/parse_3gpp_v2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsN_lkIyCLfw",
        "colab_type": "text"
      },
      "source": [
        "# Parse 3GPP document\n",
        "2020.08.19\n",
        "\n",
        "parse_3gpp_v2b.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q9Bo-aGP5wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# parse_3gpp_v2.py\n",
        "# 2020.08.19\n",
        "#---------------------------------------------\n",
        "#  README:\n",
        "#---------------------------------------------\n",
        "#prepare data set : parse 3GPP 36523-1-f00_s07_01.txt and \n",
        "#extract sentences corresponding to \"test case name\", \"with\", \"when\", \"then\"\n",
        "#\n",
        "# SOURCE DOCUMENT\n",
        "# LTE; Evolved Universal Terrestrial Radio Access (E-UTRA) and Evolved Packet Core (EPC);\n",
        "# User Equipment (UE) conformance specification; Part 1: Protocol conformance specification\n",
        "# 3GPP TS 36.523-1\n",
        "\n",
        "# downloaded *.DOC files are here:  36523-1-f00.zip\n",
        "# we will use only of them converted to TXT format\n",
        "#\n",
        "#INPUT DATA:\n",
        "# 36523-1-f00_s07_01.txt\n",
        "#\n",
        "#36523-1-f00_s07_01.txt files was generated from \n",
        "#36523-1-f00_s07_01.DOC file located in\n",
        "#\n",
        "#OUTPUT:\n",
        "# 36523-1-f00_s07_01_tests.csv   \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSPTqA6bftP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0dd94a91-3d2c-4db6-b443-79bd136276a9"
      },
      "source": [
        "!ls -l\n",
        "# !rm *"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Aug 24 16:35 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGqlRJBZEsMe",
        "colab_type": "text"
      },
      "source": [
        "# Authenticate, create the PyDrive client, and READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTkNYef5tQlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a7c800d7-8866-4bde-e8ad-90c19d6cf4ce"
      },
      "source": [
        "### Here are the instructions how to read a file from Gdrive\n",
        "# https://buomsoo-kim.github.io/colab/2018/04/16/Importing-files-from-Google-Drive-in-Google-Colab.md/\n",
        "\n",
        "# shareble_link = 'https://drive.google.com/file/d/1jNGAf5O6U4Cr4GbWK_DpCxIuxv7-BQ2c/view?usp=sharing';  file_id = '1jNGAf5O6U4Cr4GbWK_DpCxIuxv7-BQ2c'\n",
        "\n",
        "# VZ\n",
        "# shareble_link = 'https://drive.google.com/file/d/0B1Iyay9XxksvMG9wLUpFQm1Hbnc/view?usp=sharing';  file_id = '0B1Iyay9XxksvMG9wLUpFQm1Hbnc'\n",
        "\n",
        "\n",
        "# ==============================================================================================================\n",
        "# ==============================================================================================================\n",
        "# flies in  https://drive.google.com/drive/folders/1uGpgosPngiTFpWNjr7tagS2wR6rQZsr6\n",
        "# G:\\My Drive\\__C\\Users\\khafifa\\Downloads\\TESTING_FROM_REQUIREMENTS\\36523-1-f00_s07_01.zip      #  16 MB\n",
        "# shareble_link = 'https://drive.google.com/file/d/1uKLRlQSaTn6ZvRPHoBQLzj1bbDClA_W_/view?usp=sharing'; file_id = '1uKLRlQSaTn6ZvRPHoBQLzj1bbDClA_W_'\n",
        "\n",
        "# G:\\My Drive\\__C\\Users\\khafifa\\Downloads\\TESTING_FROM_REQUIREMENTS\\36523-1-f00_s07_01.txt.zip  # 290 KB\n",
        "shareble_link = 'https://drive.google.com/file/d/1-6r3JzD0k2YHG4C1yfjWTzXAu-MRbYSh/view?usp=sharing'; file_id = '1-6r3JzD0k2YHG4C1yfjWTzXAu-MRbYSh'\n",
        "# ==============================================================================================================\n",
        "# ==============================================================================================================\n",
        "\n",
        "\n",
        "# nonVZ\n",
        "# shareble_link = 'https://drive.google.com/file/d/18agBYxgWJ4dVZGOYK1mil1RDhjvQL8e1/view?usp=sharing'; file_id = '18agBYxgWJ4dVZGOYK1mil1RDhjvQL8e1'\n",
        "\n",
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (49.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM6kog8hEect",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#see Step 6 https://buomsoo-kim.github.io/colab/2018/04/16/Importing-files-from-Google-Drive-in-Google-Colab.md/\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx_HHdnuEzXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':file_id})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('36523-1-f00_s07_01.zip') "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MchwYeW0txL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a51b7b5-b05a-4a3a-b861-3f0a00b39814"
      },
      "source": [
        "# !ls -ltra\n",
        "!unzip 36523-1-f00_s07_01.zip"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  36523-1-f00_s07_01.zip\n",
            "  inflating: 36523-1-f00_s07_01.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3KaKT5qbzZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install doc2text\n",
        "# !pip install PythonMagick"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGGnx1u7cc5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8a189869-a18e-4f61-95b3-fb48f68fbf28"
      },
      "source": [
        "!ls -ltra"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1972\n",
            "-rw-r--r-- 1 root root 1695106 Aug 13 11:56 36523-1-f00_s07_01.txt\n",
            "drwxr-xr-x 1 root root    4096 Aug 24 16:35 sample_data\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 19:29 ..\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 19:34 .config\n",
            "-rw-r--r-- 1 root root  296662 Aug 27 19:57 36523-1-f00_s07_01.zip\n",
            "drwxr-xr-x 1 root root    4096 Aug 27 19:57 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdkyBfXlcAKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import doc2text\n",
        "\n",
        "# # Initialize the class.\n",
        "# doc = doc2text.Document()\n",
        "\n",
        "# # You can pass the lang (as 3 letters code) to the class to improve accuracy\n",
        "# # On ubuntu it requires the package tesseract-ocr-$lang$\n",
        "# # On other OS, see https://github.com/tesseract-ocr/langdata\n",
        "# doc = doc2text.Document(lang=\"eng\")\n",
        "\n",
        "# # Read the file in. Currently accepts pdf, png, jpg, bmp, tiff.\n",
        "# # If reading a PDF, doc2text will split the PDF into its component pages.\n",
        "\n",
        "# # !more RespondentTypeREADME.txt\n",
        "# wd = './'\n",
        "# # txt_file_name = wd+'36523-1-f00_s07_01.txt'\n",
        "# doc_file_name = wd+'36523-1-f00_s07_01.doc'\n",
        "\n",
        "# # doc.read('./path/to/my/file')\n",
        "# doc.read(file_name)\n",
        "\n",
        "# # Crop the pages down to estimated text regions, deskew, and optimize for OCR.\n",
        "# doc.process()\n",
        "\n",
        "# # Extract text from the pages.\n",
        "# doc.extract_text()\n",
        "# text = doc.get_text()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgpo63p_uGue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !more RespondentTypeREADME.txt\n",
        "wd = './'\n",
        "file_name = wd+'36523-1-f00_s07_01.txt'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGds5v-eFOi1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5746782c-2463-4efa-8f65-cc8246b259b9"
      },
      "source": [
        "# to deal with non-ascii codes read this\n",
        "# https://stackoverflow.com/questions/22216076/unicodedecodeerror-utf8-codec-cant-decode-byte-0xa5-in-position-0-invalid-s\n",
        "# import codecs      # f = codecs.open(file_name, \"r\", encoding= 'unicode_escape')\n",
        "# file_name = '36523-1-f00_s07_01.txt'\n",
        "with open(file=file_name, mode='r', encoding='unicode_escape') as f:\n",
        "    lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "printable = set(string.printable)\n",
        "lines2 = [  ''.join(filter(lambda x: x in printable, s)) for s in lines  ]\n",
        "assert len(lines2)==len(lines)\n",
        "print(len(lines))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EWKProuSBUh",
        "colab_type": "text"
      },
      "source": [
        "# TAKE A LOOK AT DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRUvV7jR2OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "5006ef07-82ed-42a5-e933-e070b8e9a3ec"
      },
      "source": [
        "# Show a few lines describing a test case\n",
        "k=218\n",
        "lines[k-4:k+10]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '7.1.1.1.3.3\\tSpecific message contents\\n',\n",
              " 'None.\\n',\n",
              " '7.1.1.1a\\tCCCH mapped to UL SCH/ DL-SCH / UE Cat 0\\n',\n",
              " '7.1.1.1a.1\\tTest Purpose (TP)\\n',\n",
              " '(1)\\n',\n",
              " 'with { UE in E-UTRA RRC_IDLE state }\\n',\n",
              " 'ensure that {\\n',\n",
              " '  when { UE receives a Paging message including a matched identity }\\n',\n",
              " '    then { UE responds with a RRCConnectionRequest message in a MAC PDU on UL SCH on CCCH indicating LCID \\x9201011\\x92  }\\n',\n",
              " '            }\\n',\n",
              " '\\n',\n",
              " '7.1.1.1a.2\\tConformance requirements\\n',\n",
              " 'References: The conformance requirements covered in the current TC are specified in: TS 36.321, clause 5.3.3, 5.11, 6.1.2 and 6.2.1.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGupeoExR7bQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "521d8abe-7124-4fb2-f50e-634c3c9a947f"
      },
      "source": [
        "# Some 'with' are followed by '{', some by '('\n",
        "print(lines[220].strip())\n",
        "print(lines[16000].strip())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "with { UE in E-UTRA RRC_IDLE state }\n",
            "with ( UE in E-UTRA RRC_CONNECTED state )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mXvbTr7w5Xz",
        "colab_type": "text"
      },
      "source": [
        "# PARSING/SEARCH/REGEX FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYEveiHIw4Jw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3717d3d0-77fe-4800-a9a5-32b62ed78a31"
      },
      "source": [
        "# find line numbers that contain PATTERN\n",
        "def find_lineNums(lines, pattern):\n",
        "    test_idx = []\n",
        "    for i in range(len(lines)):\n",
        "      line = lines[i].strip();  # print(line)\n",
        "      if line.find(pattern) >=0 :\n",
        "        test_idx.append(i)\n",
        "    return test_idx\n",
        "\n",
        "PATTERN = \"Test Purpose (TP)\"\n",
        "test_idx = find_lineNums(lines=lines, pattern= PATTERN)    \n",
        "print(test_idx)\n",
        "print(\"patterns found =\",len(test_idx))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36, 218, 352, 508, 873, 1087, 1243, 1596, 1949, 2241, 2621, 2782, 2973, 3196, 3435, 3725, 4275, 5016, 5605, 5754, 6360, 6621, 6707, 6933, 7193, 7507, 7807, 8127, 8250, 8544, 9076, 9544, 10221, 10660, 11099, 11743, 12380, 12620, 13509, 13656, 14067, 14273, 15027, 15295, 15383, 15532, 15998, 16568, 16809, 17228, 17548, 17768, 18205, 18605, 18918, 19220, 19883, 20194, 20455, 20758, 21173, 21646, 21989, 22399, 22661, 23370, 23385, 23748, 24075, 24312, 24649, 24963, 25424, 25460, 25765, 26315, 26532, 26903, 27753, 27920, 28137, 28320, 28428, 28535, 28926, 29245, 29564, 29878, 30213, 30548, 34821, 38947, 43126, 47278, 51785, 56037, 61926, 67310, 72686, 78107, 83529, 84824, 86116, 92189, 93231, 94224, 98418, 99255, 99901, 100314, 100705, 101044, 101333, 101881]\n",
            "patterns found = 114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdlHsACwKqQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0baa0b48-5607-46bc-a152-46328c704920"
      },
      "source": [
        "import re\n",
        "R = re.compile(r\"^\\(\\d+\\)\")\n",
        "\n",
        "#for line in lines:\n",
        "#    M = R.search(line)\n",
        "#    if M:\n",
        "#        print(M.string)\n",
        "# keep looking for '(\\d)' until find 'Conformance requirements'\n",
        "# or the next test (ix2)\n",
        "def find_idx_subtests(ix1,ix2):\n",
        "  ix_subtest = []\n",
        "  for i in range(ix1,ix2):\n",
        "    M = R.search(lines[i])\n",
        "    if M:\n",
        "      #lines[i][0]=='(':\n",
        "      ix_subtest.append(i)\n",
        "      # print('==> lineNum =',i, \"  line=\", lines[i].strip())\n",
        "    if lines[i].find(\"Conformance requirements\") >=0 :\n",
        "        ix_subtest.append(i)   #conf_req_line = i\n",
        "        break;\n",
        "  return ix_subtest\n",
        "#%%\n",
        "k=46\n",
        "ix1=test_idx[k]; ix2=test_idx[k+1]\n",
        "subtests = find_idx_subtests(ix1, ix2)  \n",
        "for p in range(len(subtests)):\n",
        "    print(subtests[p], '    ',lines[subtests[p]].strip() )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15999      (1)\n",
            "16006      (2)\n",
            "16013      (3)\n",
            "16020      (4)\n",
            "16026      (5)\n",
            "16033      (6)\n",
            "16039      (7)\n",
            "16045      (8)\n",
            "16052      7.1.4.6.2\tConformance requirements\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjLp9jmgyDPt",
        "colab_type": "text"
      },
      "source": [
        "# BUILD A DATA FRAME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9_yKa55oi7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8f60f0c7-a2f4-44d6-ae4a-b62f69eb083a"
      },
      "source": [
        "d = pd.DataFrame(columns=['doc','test_sec', 'test_name', 'test_num',  'with', 'when', 'then'])\n",
        "doc_name = file_name.split('.')[0]\n",
        "#d.loc[0] = ['7.1.1.1',  'CCCH mapped to','1', 'with aa', 'when bb', 'then cc'] \n",
        "\n",
        "# BUILD THE DATA BASE\n",
        "df_index = 0\n",
        "for k in range(len(test_idx)-1):\n",
        "    ix=test_idx[k]\n",
        "    ix2=test_idx[k+1]\n",
        "    #def update_df(ix):\n",
        "    [sec_num, test_name] = lines[ix-1].strip().split('\\t')\n",
        "    ix_subtests = find_idx_subtests(ix,ix2)\n",
        "    for p in range(len(ix_subtests)-1):\n",
        "        index = ix_subtests[p]\n",
        "        \n",
        "        with_kw = when_kw = then_kw = ''\n",
        "        while index < ix_subtests[p+1]:\n",
        "            line = lines[index].strip()\n",
        "            if line.find('with') >=0 :\n",
        "                with_kw = line[len('with'):].strip()[1:-1].strip()\n",
        "            if line.find('when') >=0 :\n",
        "                when_kw = line[len('when'):].strip()[1:-1].strip()\n",
        "            if line.find('then') >=0 :\n",
        "                then_kw = line[len('then'):].strip()[1:-1].strip()\n",
        "            index += 1\n",
        "            \n",
        "        d.loc[df_index] = [doc_name, sec_num,  test_name, p+1, with_kw, when_kw, then_kw] \n",
        "        df_index += 1\n",
        "\n",
        "print(d.shape)\n",
        "d.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(279, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>test_sec</th>\n",
              "      <th>test_name</th>\n",
              "      <th>test_num</th>\n",
              "      <th>with</th>\n",
              "      <th>when</th>\n",
              "      <th>then</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_IDLE state and after transmit...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE discards the MAC PDU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE forwards to upper layers the disassembled a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1a</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / UE Cat 0</td>\n",
              "      <td>1</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "      <td>UE receives a Paging message including a match...</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.2</td>\n",
              "      <td>DTCH or DCCH mapped to UL SCH/ DL-SCH / Reserv...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_Connected state with DRB [Log...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE shall not forward the disassembled and demu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.2</td>\n",
              "      <td>DTCH or DCCH mapped to UL SCH/ DL-SCH / Reserv...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE shall forward the disassembled and demultip...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  doc  ...                                               then\n",
              "0      ...                            UE discards the MAC PDU\n",
              "1      ...  UE forwards to upper layers the disassembled a...\n",
              "2      ...  UE responds with a RRCConnectionRequest messag...\n",
              "3      ...  UE shall not forward the disassembled and demu...\n",
              "4      ...  UE shall forward the disassembled and demultip...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TeLUzfyUv2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wd='./'\n",
        "d.to_csv(wd+doc_name+'_tests.csv')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgEgseMTzHvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #%% GENERATE TRAIN AND TEST SETS\n",
        "# import numpy as np\n",
        "# txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))\n",
        "# lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )\n",
        "\n",
        "# assert len(lbl)==len(txt)\n",
        "\n",
        "# # Shuffle and split\n",
        "# idx = np.random.permutation(len(txt))\n",
        "# x,y = txt[idx], lbl[idx]\n",
        "# df=pd.DataFrame({'sentence':x,'label':y})"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7V_Hho7UnPM",
        "colab_type": "text"
      },
      "source": [
        "# SPLIT DATA FRAME INTO TRAIN AND TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmsD69flTgJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a61be6a9-df7d-4b59-e1df-fac8c46aa658"
      },
      "source": [
        "np.random.seed(seed=60)\n",
        "# idx = np.random.permutation(d.shape[0])\n",
        "\n",
        "test_rows_num = 5\n",
        "# test_rows = random.sample( range(0,d.shape[0]), test_rows_num ) \n",
        "# test_rows=[0,1,2]\n",
        "test_rows= [156, 253, 209, 43, 271]\n",
        "print('test_rows=', test_rows)\n",
        "d_test = d.iloc[test_rows]\n",
        "d_train = d.drop(test_rows)\n",
        "\n",
        "def get_X_Y(d):\n",
        "    txt = np.array(list(d['with'])    + list(d['when'])    + list(d['then']))\n",
        "    lbl = np.array([0]*len(d['with']) + [1]*len(d['when']) + [2]*len(d['then']) )\n",
        "    return txt, lbl\n",
        "\n",
        "idx = np.random.permutation(len(d_train))\n",
        "X_train, y_train = get_X_Y(d_train.iloc[idx])\n",
        "X_test,  y_test  = get_X_Y(d_test)\n",
        "\n",
        "assert(len(X_train)==len(y_train))\n",
        "assert(len(X_test)==len(y_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_rows= [156, 253, 209, 43, 271]\n",
            "822\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e1okc7B8il_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBPtceT38lJy",
        "colab_type": "text"
      },
      "source": [
        "# VECTORIZE DATA AND TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wm7QGyc8jup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set\n",
        "X_test_counts  = count_vect.transform(X_test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFa2mPI28vpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c0b3a70-df45-4e0a-8e46-e99e39abfc65"
      },
      "source": [
        "#%% XGBoost: XGB \n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)\n",
        "\n",
        "xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.005 ).fit(X_train_counts, y_train)\n",
        "predicted = xgbmodel.predict(X_test_counts)\n",
        "res=np.mean(predicted == y_test)\n",
        "print(res)\n",
        "#oac_df.loc['XGB']=res"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi792nIMcapX",
        "colab_type": "text"
      },
      "source": [
        "# ILLUSTRATE PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-GCjE7ybPkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=156\n",
        "# print(d_test.loc[k])\n",
        "requirement=[d_test['then'][k], d_test['with'][k], d_test['when'][k]]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJFobftgMfkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e6cda28-a0b9-4c11-c39a-083e84591f4b"
      },
      "source": [
        "print('REQUIREMENT =',requirement )\n",
        "pred= xgbmodel.predict(count_vect.transform(requirement))\n",
        "print('PREDICT=',pred)\n",
        "res = {pred[0]:requirement[0], pred[1]:requirement[1], pred[2]:requirement[2]}\n",
        "# res"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REQUIREMENT = ['UE flushes UL HARQ buffer', 'UE  in E-UTRA RRC_CONNECTED state', 'UE MAC is reset, due to handover to a new cell']\n",
            "PREDICT= [2 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdKv536NbOmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b35e1d9-27ff-4a7e-964c-6a0462d8297d"
      },
      "source": [
        "TEST_CASE = 'WITH ('+res[0]+')' +\\\n",
        "            ' WHEN ('+res[1]+')' +\\\n",
        "            ' THEN ('+res[1]+')'\n",
        "TEST_CASE"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'WITH (UE  in E-UTRA RRC_CONNECTED state) WHEN (UE MAC is reset, due to handover to a new cell) THEN (UE MAC is reset, due to handover to a new cell)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvf1b9wRdmGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7irhA-0g0wTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a4135f00-5ec5-4485-9976-5add774b68dc"
      },
      "source": [
        "# print(X_test)\n",
        "print(y_test)\n",
        "print(predicted)\n",
        "\n",
        "def compare_tuples(test_rows_num, y_test, predicted):\n",
        "  test_tuples = []\n",
        "  pred_tuples = []\n",
        "  for k in range(test_rows_num):\n",
        "    test_tuples.append([y_test[k], y_test[k+test_rows_num], y_test[k+2*test_rows_num]])\n",
        "    pred_tuples.append([predicted[k], predicted[k+test_rows_num], predicted[k+2*test_rows_num]])\n",
        "\n",
        "  d_tuples = pd.DataFrame( {'test_tuples':test_tuples, 'pred_tuples':pred_tuples} )\n",
        "  d_tuples['match']=d_tuples['test_tuples']==d_tuples['pred_tuples']\n",
        "  return d_tuples\n",
        "\n",
        "compare_tuples(test_rows_num, y_test, predicted)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n",
            "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_tuples</th>\n",
              "      <th>pred_tuples</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_tuples pred_tuples  match\n",
              "0   [0, 1, 2]   [0, 1, 2]   True\n",
              "1   [0, 1, 2]   [0, 1, 2]   True\n",
              "2   [0, 1, 2]   [0, 1, 2]   True\n",
              "3   [0, 1, 2]   [0, 1, 2]   True\n",
              "4   [0, 1, 2]   [0, 1, 2]   True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGhiB7R-0_Ki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17f87b5b-a63e-4c71-eb7f-177a124cb169"
      },
      "source": [
        "X_test[y_test!=predicted]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype='<U301')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULiK1QF1K6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JABGLjTe1TsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "09362b52-1deb-4374-a151-c6f076471c21"
      },
      "source": [
        "d.head(n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>test_sec</th>\n",
              "      <th>test_name</th>\n",
              "      <th>test_num</th>\n",
              "      <th>with</th>\n",
              "      <th>when</th>\n",
              "      <th>then</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>1</td>\n",
              "      <td>UE in E-UTRA RRC_IDLE state and after transmit...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE discards the MAC PDU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / Reserved Logic...</td>\n",
              "      <td>2</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE receives a MAC PDU on DL SCH and addressed ...</td>\n",
              "      <td>UE forwards to upper layers the disassembled a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>7.1.1.1a</td>\n",
              "      <td>CCCH mapped to UL SCH/ DL-SCH / UE Cat 0</td>\n",
              "      <td>1</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "      <td>UE receives a Paging message including a match...</td>\n",
              "      <td>UE responds with a RRCConnectionRequest messag...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  doc  ...                                               then\n",
              "0      ...                            UE discards the MAC PDU\n",
              "1      ...  UE forwards to upper layers the disassembled a...\n",
              "2      ...  UE responds with a RRCConnectionRequest messag...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMw2xdm2150R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%   COPIED FROM\n",
        "# https://gitlab.verizon.com/atf/atf-development/atf-data-sciences/-/blob/master/ML_models/atf_xgb_classifier.py\n",
        "\n",
        "# df2=pd.DataFrame({'sentences':data,'labels':labels})\n",
        "def compare_classifiers_v2(X_train, y_train, X_test, y_test):\n",
        "#    VALIDATION_SPLIT = 0.3\n",
        "    # np.random.seed(seed=seedval)\n",
        "    # indices = np.arange(d2.shape[0]) # get sequence of row index\n",
        "    # np.random.shuffle(indices) # shuffle the row indexes\n",
        "    # data   = d2['sentences'][indices] # shuffle data/product-titles/x-axis\n",
        "    # labels = d2['labels'][indices]\n",
        "    # #\n",
        "    # from sklearn.model_selection import train_test_split\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_fraction, random_state=42)\n",
        "    \n",
        "#    #%% COMPARE  TRAIN  AND  TEST  SET DISTRIBUTIONS\n",
        "#    vdf=pd.concat([y_train.value_counts(normalize=True).round(3) * 100, \n",
        "#                   y_test.value_counts(normalize=True).round(3) * 100],\n",
        "#    sort =False, axis=1,ignore_index=True )\n",
        "#    vdf.columns = ['train','test']\n",
        "#    vdf.to_csv(wd+\"comp_train_and_test_lables.csv\")\n",
        "    \n",
        "    #%   ========================================================\n",
        "    # INITIALIZE OAC SUMMARY TABLE\n",
        "    # import numpy\n",
        "    models = ['NB', 'NB+TF', 'NB+TFIDF', 'SVM', 'SVM+TF', 'SVM+TFIDF', 'XGB', 'XGB+TF', 'XGB+TFIDF']\n",
        "    oacs = np.zeros(len(models))    \n",
        "    oac_df = pd.DataFrame( {'oac':oacs}, index=models )\n",
        "    oac_df    \n",
        "    \n",
        "    \n",
        "    #%  DEFINE THREE TRAIN SETS\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    count_vect = CountVectorizer()\n",
        "    X_train_counts = count_vect.fit_transform(X_train)   # Plain Train set\n",
        "    X_test_counts  = count_vect.transform(X_test)\n",
        "    \n",
        "    #%\n",
        "    from sklearn.feature_extraction.text import TfidfTransformer\n",
        "    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "    X_train_tf = tf_transformer.transform(X_train_counts)  # TF train set \n",
        "    X_test_tf  = tf_transformer.transform(X_test_counts)\n",
        "    #%\n",
        "    tfidf_transformer = TfidfTransformer()\n",
        "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)  # TFIDF Train set\n",
        "    X_test_tfidf  = tfidf_transformer.transform(X_test_counts)\n",
        "    \n",
        "    #% XGBoost: XGB \n",
        "    import xgboost as xgb\n",
        "    import warnings\n",
        "    warnings.filterwarnings(module='xgboost*', action='ignore', category=DeprecationWarning)\n",
        "    \n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_counts, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_counts, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_counts)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB']=res\n",
        "    print('XGB', res)\n",
        "    \n",
        "    #% XGBoost: XGB + TF\n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tf, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tf, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_tf)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB+TF']=res\n",
        "    print('XGB+TF', res)\n",
        "    \n",
        "    #% XGB+TFIDF\n",
        "    #xgbmodel = xgb.XGBClassifier( max_depth=3, n_estimators=300, learning_rate=0.05 ).fit(X_train_tfidf, y_train)\n",
        "    xgbmodel = xgb.XGBClassifier( max_depth=1, n_estimators=3000, learning_rate=0.01 ).fit(X_train_tfidf, y_train)\n",
        "    predicted = xgbmodel.predict(X_test_tfidf)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['XGB+TFIDF']=res\n",
        "    print('XGB+TFIDF', res)\n",
        "    \n",
        "    #% Plain NB Classifier\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "    #clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        #('tfidf', TfidfTransformer()),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB']=res\n",
        "    print('NB', res)\n",
        "    \n",
        "    #% NB iwth TF\n",
        "    # TfidfTransformer(use_idf=False)\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB+TF']=res\n",
        "    print('NB+TF', res)\n",
        "\n",
        "    #%\n",
        "#    lbls=[ x for x in set(labels)]\n",
        "#    print(lbls)\n",
        "#    cf = cmdf(y_test, predicted, lbls)\n",
        "#    cf.to_csv(wd+'xgb_tf_cf.csv')\n",
        "    \n",
        "    #% NB with TFIDF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "        ('clf', MultinomialNB()),])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['NB+TFIDF']=res\n",
        "    print('NB+TFIDF', res)\n",
        "\n",
        "\n",
        "    \n",
        "    #% Plain SVM\n",
        "    from sklearn.linear_model import SGDClassifier    \n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "    #     ('tfidf', TfidfTransformer()),\n",
        "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM']=res\n",
        "    print('SVM', res)\n",
        "\n",
        "    \n",
        "    #% SVM with TF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "        ('clf',  SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM+TF']=res\n",
        "    print('SVM+TF', res)\n",
        "    \n",
        "    #% SVM with TFIDF\n",
        "    text_clf = Pipeline([\n",
        "        ('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                              alpha=1e-3, random_state=42,\n",
        "                              max_iter=5, tol=None)), ])\n",
        "    text_clf.fit(X_train, y_train)\n",
        "    predicted = text_clf.predict(X_test)\n",
        "    res=np.mean(predicted == y_test)\n",
        "    oac_df.loc['SVM+TFIDF']=res\n",
        "    print('SVM+TFIDF', res)\n",
        "    \n",
        "    return oac_df    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_hdX8RP3529",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "1c7720e1-15ad-4c3a-fe7b-845f612f9a94"
      },
      "source": [
        "oac_df = compare_classifiers_v2(X_train, y_train, X_test, y_test)\n",
        "oac_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGB 1.0\n",
            "XGB+TF 1.0\n",
            "XGB+TFIDF 1.0\n",
            "NB 1.0\n",
            "NB+TF 1.0\n",
            "NB+TFIDF 1.0\n",
            "SVM 0.9333333333333333\n",
            "SVM+TF 1.0\n",
            "SVM+TFIDF 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>oac</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB+TF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB+TFIDF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM+TF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM+TFIDF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB+TF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGB+TFIDF</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                oac\n",
              "NB         1.000000\n",
              "NB+TF      1.000000\n",
              "NB+TFIDF   1.000000\n",
              "SVM        0.933333\n",
              "SVM+TF     1.000000\n",
              "SVM+TFIDF  1.000000\n",
              "XGB        1.000000\n",
              "XGB+TF     1.000000\n",
              "XGB+TFIDF  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kQOqlsa377f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}